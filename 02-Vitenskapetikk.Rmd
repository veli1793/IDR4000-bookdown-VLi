# Vitenskapetikk

## Falsifikasjonisme

Poppers falsifiseringskriterium bygger på at de ulike teoriene som forskerne kommer opp med må være falsifiserbare. Det vil si at hvis enkelte av oppsamlede data strider mot teorien så skal det være mulig å motsi teorien. Teorier som er laget for å passe alle data og ikke kan motsies vil bli kalt for "psuedo-science" ("ikke vitenskap"), som forskere tror på, men har ufullstendige svar. Popper kritiserte Marx og Freuds sine teorier. Om teoriene til Marx møtte motstand i testingen, så endret han litt på teorien slik at den kunne forklare motstanden til dataene. På den måten unngikk han å måtte forkaste teorien sin. Freuds sine teorier mente Popper var myter som ikke var mulig å teste, og når teorier ikke kan testes, kan de heller ikke aksepteres som "science" (vitenskap). Popper mente at det var et klart skille mellom "science" og "psuedo-science", og at hans falsifikasjonskriterium løste det han kaller "problem of demarcation" [@okasha2016; @popper1969]. Okasha mente at det ikke i det hele tatt er noe avgrensning på hva som kan kalles vitenskap, da han mener at vitenskap er en heterogen aktivitet. Han viser til at Wittgenstein mente at There is no fixed set of features that define what it is to be a 'game'. Rather there is a loose cluster of features most of which are possessed by most games. But any particular game may lack any of the features in the cluster and still be a game. (Okasha, 2016, s. 15) Okasha mente at det samme som Wittgenstein forklarer kan også gjelde for vitenskap, da forskere ikke bare forkaster teorien sin så fort den møter motstand, men av naturlige grunner forsker videre og leter etter andre forklaringer for å støtte om teorien sin. Om teorier bare skulle blitt forkastet så fort den møtte motstand, så ville vitenskapelige funn gått mye tregere. I tillegg ville det vært svært vanskelig å finne teorier som passet til de dataene man har, uten at noen av de strider imot. (Okasha, 2016) Okasha hadde også et eksempel på at på at Poppers falsifiserbarhetkriterium var tvilsom. Adams og Leverrier oppdaget en ny planet ved å bygge videre på Newton's gravitasjonsteori, som på grunn av en feil kunne blitt forkastet. Okasha mente dermed at Popper ikke kunne klandre Marx sin teori, ettersom Adams og Leverrier gjorde akkurat det samme, og som resulterte i et viktig funn. Med dette mener Okasha at det ikke ser ut til at det finnes noe avgrensning om hva som kan kalles vitenskap. Jeg mener at Okasha har rett, da det ikke er logisk å bare deduktivt vise til at den ene eller andre teorien er riktig. Verden er for uforutsigbar til at man kan være 100% sikker på om teorier er riktige eller ikke. Det er heller ikke riktig å bare avskrive en teori bare fordi den møter litt motstand, for da vektlegger man feil altfor høy verdi i forhold til det riktige. Graden av motstand eller støtte fra dataene teoriene møter på, og antall studier som har undersøkt teorien, vil vise hvor mye statistisk styrke teorien får. Det vil igjen gjøre det lettere å finne ut hvor mye vi kan stole på om denne teorien er sann.

## HD-metoden og abduksjon

HD-metoden handler om at vi ut ifra tidligere data lager en teori/hypotese som kan føre til nye funn. Om vi kan dedusere/trekke slutninger på om utvalgte data fra teorien er riktig. Hvis de utvalgte dataene gir et bekreftende svar på at teorien stemmer, så vil de dataene gi en induktiv bekreftelse på at teorien er sann. En induktiv bekreftelse vil si at teorien bekreftes til en viss grad. Grunnen til at vi sier at teorien bekreftes til en viss grad er teoriene aldri kan bekreftes til å være 100% sann. @hempel1966 forklarer dette med at fremtidige relevante data alltids kan gi andre funn enn det dataene hittil har vist. Et eksempel på dette kan være at styrketrening med tunge vekter og få repetisjoner gjør musklene våre sterkere enn styrketrening med lettere vekter og flere repetisjoner. Det er høyt sannsynlig at dette stemmer i og med at mye av forskningen viser dette, men man kan aldri bevise 100% sikkert at det er sant! For alt vi vet så kan teorien i framtiden få andre resultater som vil gi mindre sjanse for at den teorien stemmer. En kan aldri vite 100% sikkert med induksjon, men man kan tillegge teorien mer eller mindre troverdighet ut ifra hvor mye støtte den får. HD-metoden har også svakheter, for vi kan ikke dedusere data fra teorien hvis teorien handler om frekvensen for at noe kan skje. Et eksempel kan være frekvensen å få diabetes type 2 etter år med inaktivitet. Hvis man lager en graf som viser at sjansen for å få diabetes type 2 øker med for eksempel 5% for hvert år med inaktivitet, så vil man få stabil linje. Problemet er at det også er andre teorier som kan spille en rolle i utviklingen av diabetes type 2, blant annet inntak av fet og kaloririk mat. Dette kan gjøre at frekvensen av diabetes type 2 vil se helt annerledes ut i grafen. HD-metoden tar ikke hensyn til at ulike faktorer kan påvirke dataene. Den tar en empirisk test som viser om dataene er riktig overfor teorien om inaktivitet. Det finnes metoder som er ment for å løse problemet til HD-metoden, kalt Abduksjon. Abduksjon er nesten lik som HD-metoden, hvor forskjellen ligger i at Abduksjon utformer teorier som forsøker å gi den beste forklaringen til de aktuelle dataene, istedenfor å dedusere. I teoriene som blir laget kan det legges til ulike årsaker som kan forklare flere data. Teorien vil da få bedre forklaringskraft, men blir til gjengjeld mer avansert jo flere årsaker som legges til grunn for teorien. Meningen med Abduksjon er at teorien som utformes skal ha den beste forklaringskraften, men samtidig være så enkel som mulig (få årsaker i teorien). Om én teori har én årsak som forklarer to data, mens en annen teori har to årsaker som forklarer to data, så er det teorien med færrest årsaker som vinner, da den er enklest, og har like god forklaringskraft som teorien med to årsaker. Om en teori med to årsaker kan forklare tre data, så vil den teorien ha bedre forklaringskraft, men til gjengjeld være mer avansert enn teorien med en årsak. Oppsummert, hvis man skal forklare et fenomen så vil HD-metoden gå ut ifra en teori, dedusere for å se om dataene er riktig, og så gi en induktiv bekreftelse basert på hvor sannsynlig det er at teorien er sann. HD-metoden tar for seg bare en teori om gangen som skal forklare fenomenet, mens Abduksjon sammenligner flere teorier basert på enkelthet og forklaringskraft, og velger den teorien med færrest årsaker og kan forklare mest data.

## Replikasjonskrisen

Vitenskapen har vært utsatt for en krise når det gjelder å kunne replisere originale forskningsartikler. Mange artikler er rett og slett ikke repliserbare, og @bird2020 har analysert dette og kommet med sin forklaring. Det er en generell frykt for å grave opp i de artiklene som ikke er repliserbare, da det vil svekke tilliten til vitenskapen i offentligheten. For det er mange store studier som viser seg å inneholde falsk positive resultater, når hypotesene som blir brukt i seg selv gir veldig lav sjanse for å gi riktig positive resultater. Det kommer av at forskeren utelukkende baserer seg på et spesielt bevis på det fenomenet som blir forsket på, uavhengig av frekvensen av at fenomenet oppstår. Dette kalles basfrekvensfeilen. I studier som gir falske positive resultater, har ofte ikke forskeren re-testet flere ganger, så da er det stor sjanse for at forskeren kommer fram til et positivt resultat som viser seg å være falsk positiv. Om forskeren derimot velger å re-teste hypotesene, så vil nok forskeren få flere negative resultater, men til gjengjeld kunne få mer riktige resultater. Å replisere studier kan være krevende og dyrt, og som Bird nevner er det også mulighet å feile med å replisere slik at de ikke støtter suksessfulle teorier. At det repliseres lite studier innen medisin mener Bird har en sammenheng med økonomisk og moralsk press for selskaper som skal finne opp medisiner som gir resultater. Andre grunner som Bird diskuterer er lav statistisk styrke, for høy "alpha" (signifikantgrense p-verdi), publikasjonsskjevhet, tvilsom forskningspraksis og svindel. Med lav statistisk styrke så blir studier med for få forsøkspersoner trukket frem, for det vil gjøre det vanskeligere for replikasjonsstudiene å finne samme effekt. Det gjør også at vi må ha høy "alpha". Med høy statistisk styrke så kan vi senke "alpha", og dermed kunne øke PPV (sjansen for at hypotesen faktisk er sann, gitt at testingen har fått positivt utslag). Publikasjonsskjevheten viser at det er for mange studier med positivt resultat som er publisert i forhold til studier med negativt resultat. Grunner til det er at både tidsskrifter og forskere kan bare droppe å publisere artikler som ikke gir et positivt resultat. For hvis studier med negative resultater blir publisert, så vil offentligheten tvile på at hypotesen er sann. Det som er uheldig med det er at falske positive studier kan bli mer akseptert. Tvilsom forskningspraksis og svindel er også grunner til at studier ikke kan repliseres. Først og fremst er det standardiseringen studiene har hatt som er kritikkverdig, men også P-hacking hvor forskerne bruker egne programmer til å lage falske p-verdier for å kunne støtte hypotesen. I psykologiforskningen er det ofte færre folk i forskningsgruppene, så ifølge Bird får studiene i dette fagfeltet ofte gå gjennom uten å bli forøkt replisert. Bird har mye rett i det han kommer med. Det handler mye om skjevhet i publiseringen. De fleste forskere ønsker å finne noe av stor verdi, så da kommer det ikke som noe sjokk at mange legger for stor vekt på de positive resultatene, som oftest vil føre til falsk positive resultater. Som nevnt over er det også mye økonomisk press på selskaper til å finne positive resultater, som vil bidra til å kunne legge for mye vekt på de positive resultatene, samt kunne ty til svindel. Lav statistisk styrke på grunn av for få forsøkspersoner bidrar til at det blir vanskelig replisere studiene, som kan gi både type-I-feil og type-II-feil.
